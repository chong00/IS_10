+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ docker exec -it minigo python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.MINIGO)'
:::MLLOG {"namespace": "", "time_ms": 1624522688331, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "minigo", "metadata": {"file": "/opt/reinforcement/minigo/ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522688341, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/opt/reinforcement/minigo/ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522688341, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/opt/reinforcement/minigo/ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522688341, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/opt/reinforcement/minigo/ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522688341, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/opt/reinforcement/minigo/ml_perf/logger.py", "lineno": 27}}
+ '[' 1 -eq 1 ']'
+ sync
+ sudo /sbin/sysctl vm.drop_caches=3
vm.drop_caches = 3
+ docker exec -it minigo python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import log_event
log_event(key=constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1624522689649, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "/opt/reinforcement/minigo/ml_perf/logger.py", "lineno": 27}}
+ export SEED=19357
+ SEED=19357
+ docker exec -it minigo bash -c 'DGXSYSTEM=is10 SLURM_NTASKS_PER_NODE=9                                                  mpirun --use-hwthread-cpus --allow-run-as-root -np 9 ./run_and_time.sh'
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
+ set -e
+ cd minigo
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
+ set -e
+ cd minigo
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
+ set -e
+ cd minigo
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
+ set -e
+ cd minigo
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
+ set -e
+ cd minigo
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
+ set -e
+ cd minigo
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
+ set -e
+ cd minigo
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
+ set -e
+ cd minigo
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
Run vars: id 000786 gpus 4 tasks/node 9 procs/gpu 2
Running benchmark REINFORCEMENT - Minigo
STARTING TIMING RUN AT 2021-06-24 08:18:09 AM
+ set -e
+ cd minigo
+ BASE_DIR=ml_perf/mpi-results/slurm-000786
+ CHECKPOINT_DIR=/data/mlperf07
+ TARGET_PATH=/data/target/target.minigo.tf
+ python3 ./ml_perf/train_loop.py --board_size=19 --base_dir=ml_perf/mpi-results/slurm-000786 --flagfile=ml_perf/flags/19/train_loop.flags --checkpoint_dir=/data/mlperf07 --target_path=/data/target/target.minigo.tf --num_gpus_train=1 --ranks_per_node=9 --procs_per_gpu=2 --use_trt=1 --verbose=0 --selfplay_threads=6 --parallel_search=8 --parallel_inference=2 --concurrent_games_per_thread=32 --train_batch_size=4096 --suggested_games_per_iteration=8192 --iterations=70
:::MLLOG {"namespace": "", "time_ms": 1624522693879, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807481, "event_type": "POINT_IN_TIME", "key": "lr_rates", "value": [0.016, 0.16, 0.016, 0.0016], "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807481, "event_type": "POINT_IN_TIME", "key": "lr_boundaries", "value": [128, 10000, 20000], "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807481, "event_type": "POINT_IN_TIME", "key": "train_batch_size", "value": 4096, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807482, "event_type": "POINT_IN_TIME", "key": "virtual_losses", "value": 4, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807482, "event_type": "POINT_IN_TIME", "key": "seed", "value": 0, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807482, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0001, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807482, "event_type": "POINT_IN_TIME", "key": "filter_amount", "value": 0.3, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807482, "event_type": "POINT_IN_TIME", "key": "num_readouts", "value": 800, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807482, "event_type": "POINT_IN_TIME", "key": "value_init_penalty", "value": 0.2, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807482, "event_type": "POINT_IN_TIME", "key": "holdout_pct", "value": 0.0, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807483, "event_type": "POINT_IN_TIME", "key": "disable_resign_pct", "value": 0.0, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807483, "event_type": "POINT_IN_TIME", "key": "resign_threshold", "value": -0.999, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807483, "event_type": "POINT_IN_TIME", "key": "virtual_losses", "value": 4, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807483, "event_type": "POINT_IN_TIME", "key": "min_selfplay_games_per_generation", "value": 8192, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807483, "event_type": "POINT_IN_TIME", "key": "value_init_penalty", "value": 0.2, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807483, "event_type": "POINT_IN_TIME", "key": "window_size", "value": 5, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522807483, "event_type": "POINT_IN_TIME", "key": "eval_games", "value": 256, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522812593, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522812593, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27}}
:::MLLOG {"namespace": "", "time_ms": 1624522812593, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1624522812892, "event_type": "POINT_IN_TIME", "key": "actual_selfplay_games_per_generation", "value": 9240, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1624522812893, "event_type": "POINT_IN_TIME", "key": "actual_selfplay_games_per_generation", "value": 9236, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1624522812893, "event_type": "POINT_IN_TIME", "key": "actual_selfplay_games_per_generation", "value": 9258, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1624522812893, "event_type": "POINT_IN_TIME", "key": "actual_selfplay_games_per_generation", "value": 9261, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1624522812893, "event_type": "POINT_IN_TIME", "key": "actual_selfplay_games_per_generation", "value": 9212, "metadata": {"file": "./ml_perf/logger.py", "lineno": 27, "epoch_num": 18}}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1365, in _do_call
    return fn(*args)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1350, in _run_fn
    target_list, run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4096,64,19,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node batch_normalization_7/FusedBatchNormV3}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./ml_perf/train_loop.py", line 989, in <module>
    app.run(main)
  File "/usr/local/lib/python3.6/dist-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.6/dist-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "./ml_perf/train_loop.py", line 937, in main
    run_train(state, rank, tstate, tcomm, tzcomm)
  File "./ml_perf/train_loop.py", line 440, in run_train
    minigo_train.run(state, rank, tstate, num_examples, record_paths)
  File "./train.py", line 275, in run
    sess.run(train_op)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 956, in run
    run_metadata_ptr)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1359, in _do_run
    run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4096,64,19,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node batch_normalization_7/FusedBatchNormV3 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


Original stack trace for 'batch_normalization_7/FusedBatchNormV3':
  File "./ml_perf/train_loop.py", line 989, in <module>
    app.run(main)
  File "/usr/local/lib/python3.6/dist-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.6/dist-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "./ml_perf/train_loop.py", line 898, in main
    tstate = minigo_train.init_train(rank, tcomm, FLAGS.model_dir)
  File "./train.py", line 246, in init_train
    train_op = dual_net.model_fn(features, labels, tf.estimator.ModeKeys.TRAIN, FLAGS.flag_values_dict(), True)
  File "./dual_net.py", line 297, in model_fn
    features, mode == tf.estimator.ModeKeys.TRAIN, params)
  File "./dual_net.py", line 543, in model_inference_fn
    shared_output = mg_res_layer(shared_output)
  File "./dual_net.py", line 502, in mg_res_layer
    residual = residual_inner(inputs)
  File "./dual_net.py", line 496, in residual_inner
    conv_layer1 = mg_batchn(mg_conv2d(inputs))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py", line 330, in new_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py", line 327, in batch_normalization
    return layer.apply(inputs, training=training)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py", line 330, in new_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 1700, in apply
    return self.__call__(inputs, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py", line 548, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py", line 854, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 234, in wrapper
    return converted_call(f, options, args, kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 439, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 330, in _call_unconverted
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py", line 167, in call
    return super(BatchNormalization, self).call(inputs, training=training)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/normalization.py", line 659, in call
    outputs = self._fused_batch_norm(inputs, training=training)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/normalization.py", line 517, in _fused_batch_norm
    training, _fused_batch_norm_training, _fused_batch_norm_inference)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py", line 59, in smart_cond
    pred, true_fn=true_fn, false_fn=false_fn, name=name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/smart_cond.py", line 54, in smart_cond
    return true_fn()
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/normalization.py", line 503, in _fused_batch_norm_training
    data_format=self._data_format)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py", line 1501, in fused_batch_norm
    name=name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py", line 4620, in fused_batch_norm_v3
    name=name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py", line 794, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py", line 513, in new_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py", line 3357, in create_op
    attrs, op_def, compute_device)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py", line 3426, in _create_op_internal
    op_def=op_def)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()

^C